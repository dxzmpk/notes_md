# 深度学习学习路线

## 博客总结

1. [LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
2. [强化RNN](https://distill.pub/2016/augmented-rnns/#adaptive-computation-time)

![1572231668128](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1572231668128.png)

​			NTM tensorflow[实现](https://github.com/carpedm20/NTM-tensorflow)

​			ACT tensorflow[实现](https://github.com/DeNeutoy/act-tensorflow)

3. [VAE](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/)（2013）

   ### pre 自编码器原理
   
   **自编码器**由一个编码器（**encoder**）函数和一个解码器（**decoder**）函数组合而成。编码器函数将输入数据转换为一种不同的表示，而解码器函数则将这个新的表示转换到原来的形式，尽可能复现输入信号的神经网络，而为了实现这种复现，自动编码器就必须自动捕捉可以代表输入数据的最重要的因素。 
   
   **自编码器的用途**
   
   如今，数据可视化的数据降噪和降维被认为是自编码器的两个主要的实际应用。使用适当的维度和稀疏性约束，自编码器可以得到比PCA或其他类似技术更好的数据投影。
   
   自编码器通过数据示例自动学习。这意味着很容易训练在特定类型的输入中表现良好的算法的特定实例，并且不需要任何新的结构，只需适当的训练数据即可。
   
   但是，自编码器在图像压缩方面做得并不好。由于自编码器是在给定的一组数据上进行训练的，因此它将得到与所用训练集数据相似的压缩结果，但对通用的图像压缩器来说效果并不好。至少不如像JPEG这样的压缩技术。
   
   自编码器被训练以可以在输入通过编码器和解码器后保留尽可能多的信息，但也会被训练成，使新的表示具有各种不错的属性。
   
   ### VAE
   
   应用： [image generation](https://arxiv.org/abs/1502.04623) and [reinforcement learning](https://arxiv.org/abs/1509.08731) 
   
   loss function:

$$
l_i(\theta, \phi) = - \mathbb{E}_{z\sim q_\theta(z\mid x_i)}[\log p_\phi(x_i\mid z)] + \mathbb{KL}(q_\theta(z\mid x_i) \mid\mid p(z))
$$

​		**第一项**是重构误差，就是第i个点的log-likihood的期望和。它实际反映了在我们将x总结为z的时候，有多少信息被损失了。

​		例如，如果我们的目的是建模黑白图像，而我们的模型在一个实际为白点的位置对黑点给出很高的可能性，这将会导致极差的重构误差。

​		**第二项**是我们加入的正则项， Kullback-Leibler divergence on x and z。这一项用来衡量当q用来表示p的时候，有多少信息被丢失了。即衡量二者的相似度。p是一个标准的正态分布$N(0,1)$。如果encoder输出的z和正态分布不一样，将会产生误差。

​		最终的模型为一个联合概率分布，
$$
p(x,z)=p(x∣z)p(z)
$$





## 强化学习 Reinforcement [learning](https://www.bilibili.com/video/av48285039/?p=82)

概述：

environment - observation - action - reward

人（作为老师）都不知道该做什么，所以监督学习算法不适用。

先做监督学习，再做强化学习

应用：

- 聊天机器人 -- 让两个机器互相对话，通过构造一些规则，来检查好还是不好
- Flying Helicoper
- Driving
- 省电
- 产生句子
- Playing Game -- 像人一样玩，看到的东西是像素

难点：

- Reward Delay, 可能需要放弃短期利益得到总体最大利益。
- 当前的动作影响之后看到的状态，例如要探索未知的动作，才能得到新的状态。

Asynchronous Advantage Actor-Critic(A3C)

Alpha Go: policy-based + value-based + model based

### 训练过程

Actor : neural network，穷举pixel不可取。

决定actor的好坏： $\pi _\theta(s)$, $\theta$为参数
$$
Total Reward : \;\; R_\theta = \sum_{t=1}^{T}r_t
$$
由于每次的$R_\theta$不一样，所以要希望其多次游戏的期望值越大越好。

但是，游戏产生的序列可能性无穷无尽，只能用N次游戏来近似模拟，作平均。

 这里找最大值，所以使用梯度上升法，找到最好的参数，即得到最好的函数。

运算过程:
$$
\hat{R_\theta} = \sum_{\tau}R(\tau)P(\tau\mid\theta)
$$
前一项和$\theta$无关



## [Transformer](https://www.jianshu.com/p/e7d8caa13b21) 和 BERT [链接](https://www.bilibili.com/video/av73631845/?p=2&t=1324)

### 文本预处理过程

1. 读入文本，每一项是一句话
2. 建立初始字典，同时统计词频，用dict记录，这里可以根据需求甩去一些字
3. 建立自己的字典，先预留一些位置，放自己定义的$PAD,UNK,SEP,CLS,MASK,NUM$等等, 数字是应为如果将其MASK，预测肯定不准确。最终为{字，序号}样式的字典。



## Attention, Self Attention, Multi-Head [Attention](https://www.adityaagrawal.net/blog/deep_learning/attention)

### Attention

假设我们有5种车，每个车都有相应的性质。

In this example, if we determine that the new car is 70% similar to car 1, 15% similar to car 2, 10% similar to car 3, 3% similar to car 4 and 2% similar to car 5, then the value of the new car,
$$
\begin{align}
V = 0.70\ V_1 + 0.15\ V_2 + 0.10\ V_3 + 0.03\ V_4 + 0.02\ V_5
\end{align}
$$
Note that, $0.70 + 0.15 + 0.10 + 0.03 + 0.02 = 1$. This process of determining the value of the new car is called `attention`. 其含义是找到新车和旧车之间的相似性，然后其加权和将得到新车的价值。

 A vector which represents features is called the `key` vector, k. A vector which represents values is called the `value` vector, v. A vector whose value is to be determined is called the `query` vector, q. The function used to determine similarity between a query and key vector is called the attention function or the scoring function. The scoring function returns a real valued scalar. The scores are normalized, typically using softmax, such that sum of scores is equal to 1. The final value is equal to the weighted sum of the value vectors. 

### Self-Attention

![1572938198415](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1572938198415.png)

### Multi-Head Attention

![1572938326937](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1572938326937.png)


# 背景Tips

### [生成式模型和判别式模型](https://www.cnblogs.com/ranjiewen/articles/6736640.html )

有监督学习回归模型中，我们利用训练集直接对条件概率p(y|x;θ)建模，例如logistic回归就利用hθ(x) = g(θx)对p(y|x;θ)建模（其中g(z)是sigmoid函数）。假设现在有一个分类问题，要根据一些动物的特征来区分大象(y = 1)和狗(y = 0)。给定这样的一种数据集，回归模型比如logistic回归会试图找到一条直线也就是决策边界，来区分大象与狗这两类，然后对于新来的样本，回归模型会根据这个新样本的特征计算这个样本会落在决策边界的哪一边，从而得到相应的分类结果。

　　现在我们考虑另外一种建模方式：首先，根据训练集中的大象样本，我们可以建立大象模型，根据训练集中的狗样本，我们可以建立狗模型。然后，对于新来的动物样本，我们可以让它与大象模型匹配看概率有多少，与狗模型匹配看概率有多少，哪一个概率大就是那个分类。

　　判别式模型（Discriminative Model）是直接对条件概率p(y|x;θ)建模。常见的判别式模型有 线性回归模型、线性判别分析、支持向量机SVM、神经网络等。

　　生成式模型（Generative Model）则会对x和y的联合分布p(x,y)建模，然后通过贝叶斯公式来求得p(yi|x)，然后选取使得p(yi|x)最大的yi

 ![img](https://images0.cnblogs.com/blog/392228/201411/011342115036933.jpg) 

![1572515248631](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1572515248631.png)

### BERT模型代码

**![1572617649158](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1572617649158.png)**

### Fine Tuning

什么是fine-tuning？

在实践中，由于数据集不够大，很少有人从头开始训练网络。常见的做法是使用预训练的网络（例如在ImageNet上训练的分类1000类的网络）来重新fine-tuning（也叫微调），或者当做特征提取器。

以下是常见的两类迁移学习场景：

1 卷积网络当做特征提取器。使用在ImageNet上预训练的网络，去掉最后的全连接层，剩余部分当做特征提取器（例如AlexNet在最后分类器前，是4096维的特征向量）。这样提取的特征叫做CNN codes。得到这样的特征后，可以使用线性分类器（Liner SVM、Softmax等）来分类图像。

2 Fine-tuning卷积网络。替换掉网络的输入层（数据），使用新的数据继续训练。Fine-tune时可以选择fine-tune全部层或部分层。通常，前面的层提取的是图像的通用特征（generic features）（例如边缘检测，色彩检测），这些特征对许多任务都有用。后面的层提取的是**与特定类别有关的特征**，因此fine-tune时常常只需要Fine-tuning后面的层。

**预训练模型**

在ImageNet上训练一个网络，即使使用多GPU也要花费很长时间。因此人们通常共享他们预训练好的网络，这样有利于其他人再去使用。例如，Caffe有预训练好的网络地址[Model Zoo](https://modelzoo.co/)。

**何时以及如何Fine-tune**

决定如何使用迁移学习的因素有很多，这是最重要的只有两个：新数据集的大小、以及新数据和原数据集的相似程度。有一点一定记住：网络前几层学到的是通用特征，后面几层学到的是与类别相关的特征。这里有使用的四个场景：

1、新数据集比较小且和原数据集相似。因为新数据集比较小，如果fine-tune可能会过拟合；又因为新旧数据集类似，我们期望他们高层特征类似，可以使用预训练网络当做特征提取器，用提取的特征训练线性分类器。

2、新数据集大且和原数据集相似。因为新数据集足够大，可以fine-tune整个网络。

3、新数据集小且和原数据集不相似。新数据集小，最好不要fine-tune，和原数据集不类似，最好也不使用高层特征。这时可以使用前面层的特征来训练SVM分类器。

4、新数据集大且和原数据集不相似。因为新数据集足够大，可以重新训练。但是实践中fine-tune预训练模型还是有益的。新数据集足够大，可以fine-tune整个网络。

**实践建议**

预训练模型的限制。使用预训练模型，受限于其网络架构。例如，你不能随意从预训练模型取出卷积层。但是因为参数共享，可以输入任意大小图像；卷积层和池化层对输入数据大小没有要求（只要步长stride fit），其输出大小和属于大小相关；全连接层对输入大小没有要求，输出大小固定。

学习率。与重新训练相比，fine-tune要使用更小的学习率。因为训练好的网络模型权重已经平滑，我们不希望太快扭曲（distort）它们（尤其是当随机初始化线性分类器来分类预训练模型提取的特征时）。





