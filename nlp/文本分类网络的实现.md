# 文本分类网络的实现

## 卷积神经网络为什么有用？

具有卷积层和池层的网络对于分类任务很有用，在分类任务中，我们希望找到有关类成员身份的强大局部线索，但是这些线索可以出现在输入中的不同位置。 […]我们想了解某些单词序列是该主题的良好指示，而不必关心它们出现在文档中的位置。 卷积和池化层允许模型学习查找此类局部指标，而不管其位置如何。

## GNN

全称为Graph neural network, 之前的方法存在的问题：

- 固定的语料图结构，不支持在线测试，且消耗很多内存

本文提出的方法为每一个输入的文本建立一个图，而不是为整个语料库建立一个图。

结果评价：我们的模型比现存的模型表现更好但是只需要消耗更少的内存。

平时常用的CNN、RNN文本分类方法实际上网络的作用就是来表示文本。真正的分类是通过最终的前向神经网络来实现的。

GNN的用途：文本分类，序列标注，NMT，relational reasoning

Graph Convolutional Neural Network比传统的CNN模型表现更好。然后，由Yao et al.通过添加文章和节点和带权值边，得到了比当前最好结果还要优秀的结果。

然而，以上的方法都使用为所有的语料库构建一张图的方法，这会在实际中产生这样的问题：首先，因为有很多的边，所以会消耗很高的内存。而且，每一个边有固定的权值，这会在无形中限制了边的表达能力。第二，对这样的模型使用在线测试是很难的，因为这个图的机构和参数会取决于语料库，在训练之后无法被修改。

为了解决这个问题，我们提出了一个新的基于GNN的文本分类方法，我们没有为单个语料库建立图，二是为每一个输入的文本建立一个文本级别的图，对于一个文本级别的图，我们在一个文本的很小的窗口中将单词节点连接起来，而不是直接把所有节点连接。最终，我们综合图中的所有节点，来预测结果。通过我们的设计，文本级别的图会移除单个文本和整个语料库之间存在依赖关系的负担，这会使得在线测试成为可能。除此之外，它通过在更小的上下文窗口中连接单词节点的方式，只需要占据更少的内存，因为它排除了许多的和当前单词相距较远的单词，所以显著地减少了边的数量。消息传递的机制使得图中的节点将信息保留在其周围，从而在特定的上下文中将信息保留在其周围。
在我们的实验中，我们的方法在几个文本分类数据集上都实现了最先进的结果，而且和之前的方法相比消耗更少的资源。/

## GNN的提出

##  Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering 

简介：从低维度的网格图和高维度的不规则的领域中构建CNN，低维空间例如图像、音视频等，高维空间如用图表示社交网络，神经网络图或者词嵌入等。我们以谱图理论为基础，提出了一种形式的CNN，为设计图上的快速局部卷积滤波器提供了必要的数学背景。重要的是，提出的技术和原始的CNN具有同样的线性复杂度和常数级的学习复杂度。

CNN可以提取数据中的特征，而不论这种特征出现在什么空间位置。局部核或压缩的核指代那些可以独立于输入的数据大小来采集局部特征的过滤器，这里需要一个支持尺寸，这个尺寸远小于输入的尺寸。图可以编码复杂的集合结构，而且可以使用强大的工具例如谱图理论来学习。

为图构造CNNs是不够直观的，因为卷积和池化操作只为规则的网格定义。这使得这个扩展很有挑战性，既在理论上又在实现上。将CNN构建为图主要的瓶颈和首要的目标是定义评估和学习起来简单的局部图过滤器。

**提出的主要技术**

为图建立CNN有三步：第一步，在图上设计局部卷积核。第二步，将图粗粒度化，也就是把相似的节点聚集在一起。最后一步是将图池化，以空间分辨率换取更高的过滤器分辨率。

**结论**

在本文中，我们提出了一个全新的文本分类方法，Text GCN，我们建立了一个包含众多信息的词-文档矩阵，然后将文本分类任务转化为节点分类任务。TextGCN 模型可以捕捉全局的词共现信息并且很好地利用有限的有标注文本。一个基本的两层Text GCN的实现就可以在很多标准的数据集上超越其他最先进方法。

**方法介绍**

GCN是一个多层神经网络，可以直接在在图上进行操作，并产生节点的词嵌入向量

# 图卷积神经网络的实现

在图上实现机器学习算法十分复杂，因为其高度复杂性。本文是一系列文章中的第一篇，旨在介绍如何使用图卷积神经网络在图上作深度学习。[系列一]( https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780 ) [系列二](https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0)

![img](https://miro.medium.com/max/432/1*hLSeJjZHD3k_pcgHDQbC9g.gif)

![1575856963757](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1575856963757.png)

## 图的构建过程：

$G = (V,E)$. V是节点，E是所有的边，这里每一个节点都默认与自己相连。

X为一个n*m形状的节点特征矩阵，n为节点的数目，m为节点的特征的向量表示

A是G的相邻矩阵，形状为n*n，如果节点i和j相邻，则A中(i,j)为1，由于每一个节点默认都和自己相连，所以对角线都为1

D是每个节点的度矩阵，记录每个节点相邻节点的数目，形状为(n,n)，例如节点i有k个相邻节点，则D中(i,i)的值为k。

GCN的第一层：

![1575938267346](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1575938267346.png)

其中

![1575938422553](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1575938422553.png)

这里的$W_0$是参数矩阵，$\rho$是激活函数。

L为新的节点特征矩阵，形状为n*k，这是因为参数矩阵W的形状为 n * k, 所以最终节点特征的维度取决于参数矩阵W的维度。

GCN的第二层：

![1575939032703](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1575939032703.png)

通过多层的叠加，可以捕捉更长距离的相邻关系。

以文档、单词为节点的图构建如下:

![1575939338212](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1575939338212.png)

初始状态下，将X设为单位矩阵I, 即所有的文档或者单词都被表示成了one-hot向量。

图中有两种边：

1. 文档-单词之间的边权值为单词在该文档中的DF-IDF.
2. 单词和单词之间的边取决于两个单词在整个语料库中的共现情况。这种共现情况是通过一个固定大小的滑动窗口实现的。边的权重为PMI（point-wise mutual information ）

最终得到图的相邻矩阵如下：

![1575940302104](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1575940302104.png)

![1575940312409](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1575940312409.png)

其中，#W(i)是整个语料库中包含单词i的窗口数目，#W(i,j)是整个语料库中既包含i又包含j的窗口数目。

当PMI值为正，说明两个点之间的相关性比较高，当为负值时说明二者相关性比较低，这里只将正值的边加入到图中。

建立图之后，将图作为GCN的输入，公式如下：

![1575940878347](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1575940878347.png)

$W_1$的维度为n*类别的数目。得到的Z形状和$W_1$一样，最终使用softmax分类器就能得到分类的结果。

训练过程使用交叉熵来衡量损失，

![1575941065035](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1575941065035.png)

其中$y_D$为有标签的文档的数目，F为类别的数目。

实验结果：                      

![1575941932699](C:\Users\YOGA710\AppData\Roaming\Typora\typora-user-images\1575941932699.png)

